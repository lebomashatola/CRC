{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e0b085-4eff-42dc-bf8d-17594a2917af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gudhi\n",
    "import dcor\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gudhi import RipsComplex\n",
    "from sklearn import preprocessing\n",
    "from gudhi.representations import Landscape, PersistenceImage\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca623f-df49-4d1d-a7b4-c6112d0988c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ GENE EXPRESSION MATRICES AS PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95152fa1-1b00-46ac-85bb-7c98d33f1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_rna_dataframe(path, ref):\n",
    "    \n",
    "    labelencoding = preprocessing.LabelEncoder()\n",
    "    \n",
    "    file_directory = '/directory/' + path\n",
    "    df = pd.read_pickle(file_directory)\n",
    "    \n",
    "    df.index = [ref] * df.shape[0]\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b48ccce-d501-426c-9de8-f9e07bfe3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5851c3aa-0d69-46b3-ba0c-9b325278eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(case, control, name):\n",
    "    \n",
    "    X_new = pd.concat([case, control])\n",
    "    filepath = '/directory/' + name\n",
    "    \n",
    "    biomarkers = pd.read_csv(filepath, index_col=0) \n",
    "    biomarkers = biomarkers[\"x\"].to_numpy()    \n",
    "    X_new = X_new[np.intersect1d(X_new.columns, biomarkers)] \n",
    "    \n",
    "    labelencoding = preprocessing.LabelEncoder()\n",
    "    gene_exprs_matrix = pd.concat([case, control], axis=0)\n",
    "    labs = labelencoding.fit_transform(gene_exprs_matrix.index.to_list())\n",
    "    \n",
    "    train, test = train_test_split(X_new, test_size=0.3, train_size=0.7, shuffle=True, randon_state=0)\n",
    "            \n",
    "    train_labs = labelencoding.fit_transform(train.index.to_list())\n",
    "    test_labs = labelencoding.fit_transform(test.index.to_list())\n",
    "    \n",
    "    return (np.array(train), np.array(test), train_labs, test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3da956d-2e5f-49e7-86a5-68b43fbb2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26dd979a-b5eb-4ef2-a519-0d438b581f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intergene_correlation_measure(DF):\n",
    "    \n",
    "    num_genes = DF.shape[1]\n",
    "    dist = np.zeros((num_genes, num_genes))\n",
    "    \n",
    "    for i in range(num_genes):\n",
    "        \n",
    "        for j in range(i+1, num_genes):\n",
    "            \n",
    "            dist[i,j] = dcor.distance_correlation(DF[:,i], DF[:,j]) #Distance Correlations \n",
    "    \n",
    "    dist = dist + dist.T + np.eye(num_genes)\n",
    "    \n",
    "    return 1 - dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34403515-a5ec-47cd-a745-c15468701449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per-patient Distance Correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fd2f4e9-d2bb-4916-9781-f89f127b91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_correlation_measure(F, M):\n",
    "    \n",
    "    F = F.T\n",
    "    num_genes = M.shape[1]\n",
    "    dist = np.zeros((num_genes, num_genes))\n",
    "        \n",
    "    for i in range(num_genes):\n",
    "        for j in range(i+1, num_genes):\n",
    "            \n",
    "            dist[i,j] = M[i,j] + (F[i] + F[j]) \n",
    "            \n",
    "    dist = dist + dist.T + np.eye(num_genes)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0852c2b0-da18-4c49-81d9-0d80dec152b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Persistent Homology Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c11fa64d-8326-49c6-8bfc-104a06de4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplicial_patient(X, M):\n",
    "    \n",
    "    Persistent_diagrams0, Persistent_diagrams1, Persistent_diagrams2 = [], [], []\n",
    "    \n",
    "    for s in X:\n",
    "        \n",
    "        distance_matrix = patient_correlation_measure(s, M)\n",
    "        rips_complex = RipsComplex(distance_matrix).create_simplex_tree(max_dimension=1) #Weights used include per-patient gene expressions\n",
    "        \n",
    "        rips_complex.collapse_edges()\n",
    "        rips_complex.expansion(3)\n",
    "        rips_complex.persistence()\n",
    "        \n",
    "        diag = rips_complex.persistence()\n",
    " \n",
    "        Persistent_diagrams0.append(rips_complex.persistence_intervals_in_dimension(0))\n",
    "        Persistent_diagrams1.append(rips_complex.persistence_intervals_in_dimension(1))\n",
    "        Persistent_diagrams2.append(rips_complex.persistence_intervals_in_dimension(2))\n",
    "    \n",
    "    %config InlineBackend.figure_format = 'retina'\n",
    "    gudhi.plot_persistence_diagram(diag)\n",
    "    remove_infinity = lambda barcode : np.array([bars for bars in barcode if bars[1]!= np.inf])\n",
    "    \n",
    "    image = PersistenceImage(resolution=resolution) \n",
    "    \n",
    "    samplelandscape0img = image.fit_transform(Persistent_diagrams0)\n",
    "    samplelandscape1img = image.fit_transform(Persistent_diagrams1)\n",
    "    samplelandscape2img = image.fit_transform(Persistent_diagrams2)\n",
    "    \n",
    "        \n",
    "    return np.column_stack((samplelandscape0img, samplelandscape1img, samplelandscape2img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b67146-3419-4fb5-9973-f329a63ce1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88c51d66-cc13-48ac-b714-dea5560918ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPClass(X_train, X_test, y_train, y_test, lbl):\n",
    "    \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    parameter_space = {\n",
    "        \n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "    \n",
    "    mlp_gs = MLPClassifier(max_iter=2000) #Epochs 2000\n",
    "    clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=2)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict(X_test) # Test Data\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    print(lbl, 'Results on the Test Set:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    pr = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    re = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bala = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    y_predT = clf.predict(X_train) # Train Data\n",
    "    \n",
    "    f1T = f1_score(y_train, y_predT, average=\"macro\")\n",
    "    f1_micro_T = f1_score(y_train, y_predT, average=\"micro\")\n",
    "    prT = precision_score(y_train, y_predT, average=\"macro\")\n",
    "    reT = recall_score(y_train, y_predT, average=\"macro\")\n",
    "    accT = accuracy_score(y_train, y_predT)\n",
    "    balaT = balanced_accuracy_score(y_train, y_predT)\n",
    "    \n",
    "    scores = np.array([ f1*100, f1T*100, f1_micro*100, f1_micro_T*100, re*100, reT*100, pr*100, prT*100, acc*100, accT*100, bala*100, balaT*100 ])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9620ab1-7878-41a5-a287-fcf45a12def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(all_metrics,\n",
    "                       index=['BRCA', 'COAD', 'LUAD','PRAD'], \n",
    "                       columns=['F1 Score MacroTest', 'F1 Score MacroTrain',\n",
    "                                'F1 Score MicroTest', 'F1 Score MicroTrain',\n",
    "                                'RecallTest', 'RecallTrain',\n",
    "                                'PrecisionTest', 'PrecisionTrain',\n",
    "                                'AccuracyTest', 'AccuracyTrain',\n",
    "                                'BalancesAccTest', 'BalancedAccTrain'])\n",
    "\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
